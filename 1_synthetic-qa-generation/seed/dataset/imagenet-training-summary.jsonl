{"QUESTION": "How do you format and mount an EBS volume on /data and change its owner to ec2-user?", "ANSWER": "To format and mount an EBS volume on /data and change its owner to ec2-user, you can refer to the AWS documentation at https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-using-volumes.html."}
{"QUESTION": "What is the first step to download ImageNet according to the provided method?", "ANSWER": "The first step to download ImageNet according to the provided method is to go to http://www.image-net.org/, sign up, and get your own username and access key."}
{"QUESTION": "What is the size of the 'ILSVRC2012_img_train.tar' file?", "ANSWER": "The size of the 'ILSVRC2012_img_train.tar' file is 147897477120 bytes."}
[{"QUESTION": "What are the recommended EC2 instance types for distributed GPU training using Uber's Horovod or Tensorflow's DistributedStrategy?", "ANSWER": "The recommended EC2 instance types for distributed GPU training using Uber's Horovod or Tensorflow's DistributedStrategy are p3.16xlarge or p3dn.24xlarge."}, {"QUESTION": "What is the default root volume size for the Deep Learning AMI, and what is the recommended size increase?", "ANSWER": "The default root volume size for the Deep Learning AMI is 75GB, and it is recommended to increase it to 100GB to accommodate training logs and model checkpoints."}, {"QUESTION": "What can you do if you do not want to increase the root volume size of the EC2 instance?", "ANSWER": "If you do not want to increase the root volume size, you can delete some conda environments such as Theano, Chainer, Caffe, and Caffe2 after logging in to the EC2 instance."}]
[{"QUESTION": "What instance type is used for distributed GPU training in the provided context?", "ANSWER": "The instance type used for distributed GPU training in the provided context is p3dn.24xlarge."}, {"QUESTION": "How many instances are shown in the example for distributed GPU training?", "ANSWER": "The example shows 8 instances for distributed GPU training."}, {"QUESTION": "Where can you find the remaining steps for setting up distributed training with Horovod and TensorFlow?", "ANSWER": "The remaining steps for setting up distributed training with Horovod and TensorFlow can be found at https://docs.aws.amazon.com/dlami/latest/devguide/tutorial-horovod-tensorflow.html."}]
[{"QUESTION": "What is the first step to set up and download the ImageNet dataset according to the provided code snippet?", "ANSWER": "The first step to set up and download the ImageNet dataset is to export the ImageNet username using the command `export IMAGENET_USERNAME=[YOUR_USERNAME]`."}, {"QUESTION": "Where should you navigate to after exporting the ImageNet username and access key?", "ANSWER": "After exporting the ImageNet username and access key, you should navigate to the `imagenet/data` directory using the command `cd imagenet/data`."}, {"QUESTION": "What should you do if Method 1 for downloading the ImageNet dataset does not work?", "ANSWER": "If Method 1 for downloading the ImageNet dataset does not work, you should refer to the alternative method mentioned under the heading 'Method 2 (Alternative method if Method 1 does not work).'"}]
{"QUESTION": "What is the size of the 'model.ckpt-20000.data-00001-of-00002' file?", "ANSWER": "The size of the 'model.ckpt-20000.data-00001-of-00002' file is 204668736 bytes."}
{"QUESTION": "What was the learning rate (LR) at step 50 during the vd_train_log?", "ANSWER": "The learning rate (LR) at step 50 during the vd_train_log was 0.10353."}
[{"QUESTION": "What type of instances are recommended for data preparation and data transformation?", "ANSWER": "For data preparation and data transformation, it is recommended to use cheaper instances like t2.large with 1.0TB EBS volume."}, {"QUESTION": "Which instances are suggested for distributed training using Horovod?", "ANSWER": "For distributed training using Horovod, it is suggested to use multiple GPU instances like p2, p3, g3, and g4."}, {"QUESTION": "Where can you find additional information if you encounter issues such as downloading the dataset or converting raw data to the TFRecord feature set?", "ANSWER": "If you encounter issues such as downloading the dataset or converting raw data to the TFRecord feature set, you can refer to Julien Simon’s article and AWS Documentation."}]
{"QUESTION": "What is the purpose of the s3 bucket mentioned in the context?", "ANSWER": "The s3 bucket is used to store everything needed for the process, allowing you to skip step 1 if you do not want to invent the wheel again."}
[{"QUESTION": "What is the recommended EC2 instance type for storing the ImageNet dataset and why?", "ANSWER": "The recommended EC2 instance type for storing the ImageNet dataset is t2.large due to its memory size."}, {"QUESTION": "Why is an EBS volume of 1.0TB recommended for the ImageNet dataset?", "ANSWER": "An EBS volume of 1.0TB is recommended for the ImageNet dataset because ImageNet consists of 138GB for the training set and 6.3GB for the validation set, and additional space is needed for data processing."}, {"QUESTION": "Why was the resizing strategy of 256x256 chosen for the RecordIO format instead of 224x224?", "ANSWER": "The resizing strategy of 256x256 was chosen for the RecordIO format instead of 224x224 because an article shows different validation accuracy for different resizing strategies."}]
{"QUESTION": "What is the total size of the ImageNet training and validation sets combined?", "ANSWER": "The total size of the ImageNet training and validation sets combined is 144.3GB."}
{"QUESTION": "What is the first step to use TensorFlow's download script for ImageNet?", "ANSWER": "The first step to use TensorFlow's download script for ImageNet is to export your username and access key using the commands: $ export IMAGENET_USERNAME=[YOUR_USERNAME] and $ export IMAGENET_ACCESS_KEY=[YOUR_ACCESS_KEY]."}
[{"QUESTION": "What is the purpose of the script mentioned in the context?", "ANSWER": "The purpose of the script mentioned in the context is to move JPEG files from the validation set into 1,000 directories, each representing a unique category."}, {"QUESTION": "Where can the script for organizing the validation set be found?", "ANSWER": "The script for organizing the validation set can be found at the following URL: https://github.com/juliensimon/aws/blob/master/mxnet/imagenet/build_validation_tree.sh."}, {"QUESTION": "What is the initial step to prepare the validation set as described in the context?", "ANSWER": "The initial step to prepare the validation set is to create a directory named 'validation', move the ILSVRC2012_img_val.tar file into this directory, navigate into the 'validation' directory, and then extract the tar file."}]
[{"QUESTION": "What is the purpose of the script 'preprocess_imagenet.py' and how is it executed?", "ANSWER": "The purpose of the script 'preprocess_imagenet.py' is to preprocess the ImageNet dataset. It is executed using the command: python preprocess_imagenet.py --local_scratch_dir=[YOUR DIRECTORY] --imagenet_username=[imagenet account] --imagenet_access_key=[imagenet access key]."}, {"QUESTION": "How can you resize the ImageNet dataset using the provided scripts?", "ANSWER": "You can resize the ImageNet dataset using the script 'tensorflow_image_resizer.py' with the command: python tensorflow_image_resizer.py -d imagenet -i [PATH TO TFRECORD TRAINING DATASET] -o [PATH TO RESIZED TFRECORD TRAINING DATASET] --subset_name train --num_preprocess_threads 60 --num_intra_threads 2 --num_inter_threads 2."}, {"QUESTION": "What steps should be taken after data transformation to ensure data backup and availability?", "ANSWER": "After data transformation, you should create a new bucket and sync or copy the feature sets to the bucket. Additionally, you should create a snapshot of the EBS volume to ensure data backup and availability."}]
[{"QUESTION": "What should be done after data transformation according to the context?", "ANSWER": "After data transformation, a new bucket should be created and feature sets should be synced or copied to the bucket."}, {"QUESTION": "What is the next step after creating a new bucket and syncing feature sets to it?", "ANSWER": "The next step is to create a snapshot of the EBS volume."}, {"QUESTION": "Where can you find hands-on instructions for fast training of ImageNet on on-demand EC2 GPU instances with Horovod?", "ANSWER": "Hands-on instructions for fast training of ImageNet on on-demand EC2 GPU instances with Horovod can be found at https://daekeun.notion.site/Hands-on-Fast-Training-ImageNet-on-on-demand-EC2-GPU-instances-with-Horovod-eb49f580d1304082b497d91dec887dca."}]
[{"QUESTION": "What was the final loss value at step 7000 in the hvd_train_log?", "ANSWER": "The final loss value at step 7000 in the hvd_train_log was 0.624."}, {"QUESTION": "How many GPUs were used for the training mentioned in the context?", "ANSWER": "64 GPUs were used for the training mentioned in the context."}, {"QUESTION": "What was the learning rate (LR) at step 50 in the hvd_train_log?", "ANSWER": "The learning rate (LR) at step 50 in the hvd_train_log was 0.41119."}]
